import torch
import torch.nn.functional as F
from federated_learning.config.config import *
import copy
import traceback
from torch.utils.data import TensorDataset, DataLoader
from torch import nn, optim
import time
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import torch.optim as optim

def test(model, test_dataset):
    print("\n=== Testing Model ===")
    model.eval()
    test_loader = torch.utils.data.DataLoader(
        test_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False,
        num_workers=NUM_WORKERS if torch.cuda.is_available() else 0,
        pin_memory=PIN_MEMORY if torch.cuda.is_available() else False
    )
    correct = 0
    total = 0
    with torch.no_grad():
        for data, target in test_loader:
            data = data.to(device, non_blocking=True)
            target = target.to(device, non_blocking=True)
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    accuracy = correct / total
    print(f"Test Accuracy: {accuracy:.4f}, Error Rate: {1 - accuracy:.4f}")
    return 1 - accuracy

def client_update(client_model, optimizer, train_loader, epochs, global_model=None):
    """
    Update client model using local data with FedProx regularization if enabled.
    
    Args:
        client_model: The client's local model
        optimizer: The optimizer to use for training
        train_loader: DataLoader containing the client's local training data
        epochs: Number of local training epochs
        global_model: The global model for FedProx regularization (optional)
    
    Returns:
        Updated model state dictionary
    """
    print(f"\n=== Client Training ({epochs} epochs) ===")
    
    # Ensure models are on the correct device
    device = next(client_model.parameters()).device
    client_model.train()
    
    # Basic loss function
    criterion = torch.nn.NLLLoss()
    
    # FedProx setup
    use_fedprox = global_model is not None and AGGREGATION_METHOD in ['fedprox', 'fedbn_fedprox']
    
    if use_fedprox:
        print(f"Using FedProx with mu={FEDPROX_MU}")
        # Store initial global model state
        global_weights = {}
        for name, param in global_model.named_parameters():
            if param.requires_grad:
                global_weights[name] = param.clone().detach().to(device)
    
    # Training loop
    for epoch in range(epochs):
        epoch_loss = 0.0
        num_batches = 0
        total_proximal_term = 0.0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            # Move batch to device
            data = data.to(device, non_blocking=True)
            target = target.to(device, non_blocking=True)
            
            # Zero gradients
            optimizer.zero_grad()
            
            # Forward pass
            output = client_model(data)
            task_loss = criterion(output, target)
            
            # Calculate total loss with FedProx term if enabled
            if use_fedprox:
                proximal_term = 0.0
                for name, param in client_model.named_parameters():
                    if name in global_weights and param.requires_grad:
                        # L2 distance between local and global parameters
                        proximal_term += (FEDPROX_MU / 2) * torch.sum(
                            (param - global_weights[name].to(param.device)).pow(2)
                        )
                total_loss = task_loss + proximal_term
                total_proximal_term += proximal_term.item()
            else:
                total_loss = task_loss
            
            # Backward pass
            total_loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(
                client_model.parameters(), 
                max_norm=MAX_GRAD_NORM
            )
            
            # Optimizer step
            optimizer.step()
            
            # Update metrics
            epoch_loss += total_loss.item()
            num_batches += 1
            
            # Print batch progress
            if batch_idx % 10 == 0:
                print(f"Epoch {epoch+1}/{epochs} [{batch_idx}/{len(train_loader)}] "
                      f"Loss: {total_loss.item():.4f}")
        
        # Calculate average epoch metrics
        if num_batches > 0:
            avg_loss = epoch_loss / num_batches
            print(f"\nEpoch {epoch + 1}/{epochs}:")
            print(f"Average Loss: {avg_loss:.4f}")
            
            if use_fedprox:
                avg_proximal = total_proximal_term / num_batches
                print(f"Average Proximal Term: {avg_proximal:.4f}")
                
                # Calculate average distance from global model
                total_dist = 0.0
                num_params = 0
                for name, param in client_model.named_parameters():
                    if name in global_weights and param.requires_grad:
                        dist = torch.norm(param - global_weights[name].to(param.device)).item()
                        total_dist += dist
                        num_params += 1
                if num_params > 0:
                    avg_dist = total_dist / num_params
                    print(f"Average Distance from Global Model: {avg_dist:.4f}")
    
    # Final model state
    return client_model.state_dict()

def train_vae(vae, gradient_stack, epochs=5, batch_size=32, learning_rate=1e-3, device=None):
    """Train VAE on gradient data"""
    print("\n=== Training VAE ===")
    
    # Move VAE to device
    if device is None:
        device = next(vae.parameters()).device
    vae = vae.to(device)
    print(f"VAE parameters are now on device: {device}")
    
    # Create dataset and dataloader
    gradient_dataset = torch.utils.data.TensorDataset(gradient_stack.cpu())
    dataloader = torch.utils.data.DataLoader(
        gradient_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=False
    )
    
    # Initialize optimizer
    optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)
    
    # Training loop
    vae.train()
    for epoch in range(epochs):
        total_loss = 0
        num_batches = 0
        
        for batch_idx, (data,) in enumerate(dataloader):
            # Move data to device
            data = data.to(device)
            
            # Forward pass
            optimizer.zero_grad()
            recon_batch, mu, log_var = vae(data)
            
            # Compute loss
            recon_loss = F.mse_loss(recon_batch, data)
            kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
                loss = recon_loss + 0.1 * kl_loss
            
            # Backward pass
            loss.backward()
            optimizer.step()
            
            # Update metrics
            total_loss += loss.item()
            num_batches += 1
            
            # Print progress
            if batch_idx % 10 == 0:
                print(f"Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(dataloader)}, "
                      f"Loss: {loss.item():.4f}, Recon: {recon_loss.item():.4f}, KL: {kl_loss.item():.4f}")
        
        # Print epoch summary
        avg_loss = total_loss / num_batches
        print(f"Epoch {epoch+1}/{epochs} completed. Average loss: {avg_loss:.4f}")
    
    return vae

# Helper function to get process memory usage
def get_process_memory_usage():
    """Get the current process memory usage in MB"""
    try:
        import psutil
        import os
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        return memory_info.rss / (1024 * 1024)  # Convert to MB
    except ImportError:
        # Return a placeholder if psutil is not available
        return 0.0

def vae_loss(recon_x, x, mu, logvar):
    # Reconstruction loss
    BCE = F.mse_loss(recon_x, x, reduction='sum')
    
    # KL divergence
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return BCE + KLD

def train_dual_attention(gradient_features, labels, global_context=None, 
                    epochs=100, batch_size=32, lr=0.001, weight_decay=1e-4,
                    device=None, verbose=True, early_stopping=10):
    """
    Train the enhanced dual attention model to detect malicious clients based on gradient features.
    
    Args:
        gradient_features (torch.Tensor): Feature vectors for each client gradient
        labels (torch.Tensor): Binary labels (0=honest, 1=malicious)
        global_context (torch.Tensor, optional): Global context vector
        epochs (int): Number of training epochs
        batch_size (int): Batch size for training
        lr (float): Learning rate
        weight_decay (float): Weight decay for regularization
        device (torch.device): Device to train on (CPU/GPU)
        verbose (bool): Whether to print progress
        early_stopping (int): Patience for early stopping
        
    Returns:
        model (DualAttention): Trained dual attention model
    """
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import numpy as np
    from torch.utils.data import TensorDataset, DataLoader
    from federated_learning.models.attention import DualAttention
    from torch.optim.lr_scheduler import ReduceLROnPlateau
    import sklearn.metrics as metrics
    
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Convert to tensors if they're not already
    if not isinstance(gradient_features, torch.Tensor):
        gradient_features = torch.tensor(gradient_features, dtype=torch.float32)
    if not isinstance(labels, torch.Tensor):
        labels = torch.tensor(labels, dtype=torch.float32)
    
    # Move to device
    gradient_features = gradient_features.to(device)
    labels = labels.to(device)
    if global_context is not None and not isinstance(global_context, torch.Tensor):
        global_context = torch.tensor(global_context, dtype=torch.float32).to(device)
    
    # Normalize features for better comparison
    feature_mean = gradient_features.mean(dim=0, keepdim=True)
    feature_std = gradient_features.std(dim=0, keepdim=True) + 1e-6
    normalized_features = (gradient_features - feature_mean) / feature_std
    
    # Compute statistics for honest clients' features
    honest_indices = (labels == 0).nonzero(as_tuple=True)[0]
    if len(honest_indices) > 0:
        honest_features = normalized_features[honest_indices]
        honest_mean = honest_features.mean(dim=0)
        honest_std = honest_features.std(dim=0)
        # Define thresholds for anomaly detection
        upper_thresholds = honest_mean + 2 * honest_std
        lower_thresholds = honest_mean - 2 * honest_std
    else:
        # If no honest clients, use global statistics
        upper_thresholds = torch.ones_like(feature_mean[0]) * 2.0
        lower_thresholds = torch.ones_like(feature_mean[0]) * -2.0
    
    # Sample weighting to focus on difficult examples
    sample_weights = torch.ones(len(gradient_features), device=device)
    abnormal_features = torch.zeros((len(gradient_features), gradient_features.shape[1]), device=device)
    detected_patterns = torch.zeros(len(gradient_features), device=device)
    
    # Identify specific patterns for malicious detection
    n_samples = len(gradient_features)
    n_features = gradient_features.shape[1]
    
    print(f"Analyzing {n_samples} clients with {n_features} features...")
    
    # Define common attack patterns
    patterns = [
        # Single feature abnormality (e.g., scaling attack)
        lambda feat: torch.any(torch.abs(feat) > 3.0),
        
        # High variance across features (sign-flipping)
        lambda feat: torch.std(feat) > 2.5,
        
        # Multiple features outside normal bounds
        lambda feat: torch.sum((feat > upper_thresholds) | (feat < lower_thresholds)) >= 2,
        
        # Opposite signs on correlated features
        lambda feat: any(feat[i] * feat[j] < -4.0 
                         for i in range(n_features) 
                         for j in range(i+1, n_features)),
        
        # Anomalous ratios between feature pairs
        lambda feat: any(torch.abs(feat[i]/feat[j]) > 5.0 if feat[j].abs() > 1e-3 else False
                         for i in range(n_features) 
                         for j in range(i+1, n_features))
    ]
    
    # Analyze each sample for patterns
    malicious_count = 0
    detected_by_pattern = [0] * len(patterns)
    
    for i in range(n_samples):
        is_malicious = bool(labels[i].item())
        feature_vector = normalized_features[i]
        
        # Check if sample matches any defined pattern
        for p_idx, pattern_fn in enumerate(patterns):
            try:
                if pattern_fn(feature_vector):
                    abnormal_features[i] += 1
                    detected_patterns[i] = 1
                    
                    # Increase weight for this sample if it's malicious
                    if is_malicious:
                        sample_weights[i] = 2.0  # Higher weight for malicious samples with known patterns
                        detected_by_pattern[p_idx] += 1
                        
                    break
            except:
                # Skip failed pattern checks
                continue
        
        if is_malicious:
            malicious_count += 1
            
            # Feature-specific abnormality check
            for j in range(n_features):
                if feature_vector[j] > upper_thresholds[j] or feature_vector[j] < lower_thresholds[j]:
                    abnormal_features[i, j] = 1
                    
            # Check for abnormal feature pairs
            for j in range(n_features):
                for k in range(j+1, n_features):
                    # Check for unusual correlations or relationships
                    if (feature_vector[j] > upper_thresholds[j] and feature_vector[k] > upper_thresholds[k]) or \
                       (feature_vector[j] < lower_thresholds[j] and feature_vector[k] < lower_thresholds[k]):
                        # Both features are abnormal in same direction
                        abnormal_features[i, j] = 1
                        abnormal_features[i, k] = 1
                        sample_weights[i] = 2.5  # Higher weight for multi-feature patterns
    
    # Report detection results
    if malicious_count > 0:
        print(f"Found {malicious_count} malicious clients.")
        print(f"Pattern detection rate: {detected_patterns.sum().item() / malicious_count:.2f}")
        print("Detection by pattern type:")
        for i, count in enumerate(detected_by_pattern):
            print(f"  Pattern {i+1}: {count} clients")
    
    # Report weight distribution for malicious samples
    malicious_weights = sample_weights[labels == 1]
    if len(malicious_weights) > 0:
        print(f"Malicious sample weights: min={malicious_weights.min().item():.2f}, "
              f"max={malicious_weights.max().item():.2f}, "
              f"mean={malicious_weights.mean().item():.2f}")
    
    # Create dataset and dataloader
    dataset = TensorDataset(normalized_features, labels, sample_weights)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    # Initialize model
    feature_dim = gradient_features.shape[1]
    model = DualAttention(
        feature_dim=feature_dim,
        hidden_dim=64,
        num_heads=4,
        dropout=0.2
    )
    model.to(device)
    
    # Optimizer and loss
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=verbose)
    criterion = nn.BCELoss(reduction='none')  # Use 'none' to apply sample weights
    
    # Training loop
    best_loss = float('inf')
    best_model_state = None
    patience_counter = 0
    
    # Separation loss coefficient (encourage separation between honest and malicious)
    separation_coef = 0.1
    
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0.0
        predictions = []
        confidences = []
        true_labels = []
        
        for batch_features, batch_labels, batch_weights in dataloader:
            optimizer.zero_grad()
            
            # Forward pass
            trust_scores, confidence_scores = model(batch_features, global_context)
            
            # Weighted BCE loss for trust scores
            bce_loss = criterion(trust_scores, batch_labels)
            weighted_loss = (bce_loss * batch_weights).mean()
            
            # Confidence loss - encourage high confidence for correct predictions
            confidence_loss = F.binary_cross_entropy(
                confidence_scores,
                (trust_scores.detach() > 0.5).float()
            )
            
            # Separation loss - encourage wide gap between honest and malicious scores
            honest_mask = batch_labels < 0.5
            malicious_mask = ~honest_mask
            
            # Only apply separation loss if we have both honest and malicious samples
            separation_loss = 0.0
            if honest_mask.any() and malicious_mask.any():
                honest_scores = trust_scores[honest_mask]
                malicious_scores = trust_scores[malicious_mask]
                
                # Calculate the mean scores for honest and malicious clients
                mean_honest = honest_scores.mean()
                mean_malicious = malicious_scores.mean()
                
                # Penalize if the gap between means is too small
                separation_loss = max(0, 0.5 - (mean_malicious - mean_honest))
            
            # Combined loss
            loss = weighted_loss + 0.1 * confidence_loss + separation_coef * separation_loss
            
            # Backward pass and optimization
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            # Track statistics
            epoch_loss += loss.item()
            predictions.extend(trust_scores.detach().cpu().numpy())
            confidences.extend(confidence_scores.detach().cpu().numpy())
            true_labels.extend(batch_labels.cpu().numpy())
        
        # Compute metrics
        epoch_loss /= len(dataloader)
        predictions = np.array(predictions)
        confidences = np.array(confidences)
        true_labels = np.array(true_labels)
        binary_preds = (predictions > 0.5).astype(int)
        
        # Learning rate scheduling
        scheduler.step(epoch_loss)
        
        # Calculate performance metrics
        accuracy = metrics.accuracy_score(true_labels, binary_preds)
        precision = metrics.precision_score(true_labels, binary_preds, zero_division=0)
        recall = metrics.recall_score(true_labels, binary_preds, zero_division=0)
        f1 = metrics.f1_score(true_labels, binary_preds, zero_division=0)
        
        # Calculate specificity (true negative rate)
        tn, fp, fn, tp = metrics.confusion_matrix(true_labels, binary_preds, labels=[0, 1]).ravel()
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        if verbose and (epoch % 10 == 0 or epoch == epochs - 1):
            print(f"\nEpoch {epoch+1}/{epochs}:")
            print(f"Loss: {epoch_loss:.4f}")
            print(f"Accuracy: {accuracy:.4f}")
            print(f"Precision: {precision:.4f}")
            print(f"Recall: {recall:.4f}")
            print(f"F1 Score: {f1:.4f}")
            print(f"Specificity: {specificity:.4f}")
            print(f"Mean Confidence: {confidences.mean():.4f}")
        
        # Early stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
            if patience_counter >= early_stopping:
                if verbose:
                    print(f"Early stopping at epoch {epoch+1}")
                break
    
    # Load best model
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    # Final evaluation
    model.eval()
    with torch.no_grad():
        trust_scores, confidence_scores = model(normalized_features, global_context)
        predictions = trust_scores.cpu().numpy()
        confidences = confidence_scores.cpu().numpy()
        binary_preds = (predictions > 0.5).astype(int)
        true_labels = labels.cpu().numpy()
        
        accuracy = metrics.accuracy_score(true_labels, binary_preds)
        precision = metrics.precision_score(true_labels, binary_preds, zero_division=0)
        recall = metrics.recall_score(true_labels, binary_preds, zero_division=0)
        f1 = metrics.f1_score(true_labels, binary_preds, zero_division=0)
        
        # Calculate specificity (true negative rate)
        tn, fp, fn, tp = metrics.confusion_matrix(true_labels, binary_preds, labels=[0, 1]).ravel()
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        if verbose:
            print("\nFinal Model Performance:")
            print(f"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}")
            print(f"Recall: {recall:.4f}, F1: {f1:.4f}, Specificity: {specificity:.4f}")
            print(f"Mean Confidence: {confidences.mean():.4f}")
            
            # Analyze trust score distribution
            honest_scores = trust_scores[true_labels == 0]
            malicious_scores = trust_scores[true_labels == 1]
            
            print("\nTrust Score Distribution:")
            print(f"Honest clients - Mean: {honest_scores.mean().item():.4f}, Std: {honest_scores.std().item():.4f}")
            print(f"Malicious clients - Mean: {malicious_scores.mean().item():.4f}, Std: {malicious_scores.std().item():.4f}")
            
            # Analyze confidence distribution
            print("\nConfidence Distribution:")
            print(f"Overall - Mean: {confidences.mean():.4f}, Std: {confidences.std():.4f}")
            print(f"Correct predictions - Mean: {confidences[binary_preds == true_labels].mean():.4f}")
            print(f"Incorrect predictions - Mean: {confidences[binary_preds != true_labels].mean():.4f}")
    
    return model